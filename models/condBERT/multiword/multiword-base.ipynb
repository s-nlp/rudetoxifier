{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is stolen from https://github.com/uhh-lt/generative-ie/blob/master/src/masked_token_predictor_bert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install git+https://github.com/IINemo/isanlp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from transformers import BertForMaskedLM\n",
    "from transformers.tokenization_bert import BertTokenizer\n",
    "\n",
    "model_name = 'bert-base-multilingual-uncased'\n",
    "model = BertForMaskedLM.from_pretrained(model_name, cache_dir='./cache')\n",
    "res = model.cuda()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False, cache_dir='./cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(pretrained_weights)\n",
    "model_dict = torch.load('../condBERTmodel.pth', map_location=device)\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_bias = model.cls.predictions.decoder.bias.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92071b3a24dc47c6852a66268ca88cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=135007.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd98f690f8fc439fbe35021150f56d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=135007.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "from collections import defaultdict\n",
    "\n",
    "data_folder = '../../../data/jigsaw_drg/'\n",
    "toxic_train = [l.strip() for l in open(data_folder + 'train_toxic').readlines()]\n",
    "nontoxic_train = [l.strip() for l in open(data_folder + 'train_normal').readlines()]\n",
    "\n",
    "toxic_counter = defaultdict(lambda: 1)\n",
    "nontoxic_counter = defaultdict(lambda: 1)\n",
    "\n",
    "for text in tqdm(toxic_train):\n",
    "    for token in tokenizer.encode(text):\n",
    "        toxic_counter[token] += 1\n",
    "for text in tqdm(nontoxic_train):\n",
    "    for token in tokenizer.encode(text):\n",
    "        nontoxic_counter[token] += 1\n",
    "\n",
    "token_toxicities = [toxic_counter[i] / (nontoxic_counter[i] + toxic_counter[i]) for i in range(len(tokenizer.vocab))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "token_toxicities = np.array(token_toxicities)\n",
    "token_toxicities = np.maximum(0, np.log(1/(1/token_toxicities-1)))   # log odds ratio\n",
    "\n",
    "# discourage meaningless tokens\n",
    "for tok in ['.', ',', '-']:\n",
    "    token_toxicities[tokenizer.encode(tok)][1] = 3\n",
    "\n",
    "for tok in ['you']:\n",
    "    token_toxicities[tokenizer.encode(tok)][1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cls.predictions.decoder.bias = torch.nn.Parameter(torch.tensor(old_bias - token_toxicities * 10).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import masked_token_predictor_bert\n",
    "reload(masked_token_predictor_bert)\n",
    "from masked_token_predictor_bert import MaskedTokenPredictorBert\n",
    "\n",
    "from predict import analyze_tagged_text\n",
    "\n",
    "predictor = MaskedTokenPredictorBert(model, tokenizer, max_len=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dale/dialogue-censor/style_transfer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def add_sys_path(p):\n",
    "    p = os.path.abspath(p)\n",
    "    print(p)\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "add_sys_path('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transfer_utils.masking\n",
    "reload(transfer_utils.masking)\n",
    "from transfer_utils.masking import print_mask, delete_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.annotation_repr import CSentence\n",
    "from isanlp.processor_sentence_splitter import ProcessorSentenceSplitter\n",
    "from isanlp.en.processor_tokenizer_nltk_en import ProcessorTokenizerNltkEn\n",
    "from isanlp import PipelineCommon\n",
    "\n",
    "\n",
    "def create_parsers():\n",
    "    return PipelineCommon([\n",
    "        (ProcessorTokenizerNltkEn(), ['text'], {0 : 'tokens'}),\n",
    "        (ProcessorSentenceSplitter(), ['tokens'], {0 : 'sentences'})\n",
    "    ])\n",
    "    return ppl\n",
    "\n",
    "ppl = create_parsers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "\n",
    "def embed(text):\n",
    "    toks = glove_embedding.embed(Sentence(text))[0]\n",
    "    return np.mean([t.embedding.cpu().numpy() for t in toks], axis=0)\n",
    "\n",
    "def cosine(v1, v2):\n",
    "    return np.dot(v1, v2) / np.sqrt(sum(v1**2) * sum(v2**2) + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../word2coef.pkl', 'rb') as f:\n",
    "    word2coef = pickle.load(f)\n",
    "    \n",
    "def group_by_first_token(texts):\n",
    "    seqs = [tokenizer.encode(x,add_special_tokens=False) for x in texts]\n",
    "    grouped = defaultdict(list)\n",
    "    for seq in seqs:\n",
    "        grouped[seq[0]].append(seq)\n",
    "    return grouped\n",
    "\n",
    "#@title get_mask - Masks, given by dictionary\n",
    "with open(\"../negative-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "    s = list(map(lambda x: x[:-1], s))\n",
    "with open(\"../toxic_words.txt\", \"r\") as f:\n",
    "    ss = f.readlines()\n",
    "    s += list(map(lambda x: x[:-1], ss))\n",
    "neg_complex_tokens = group_by_first_token(s)\n",
    "\n",
    "with open(\"../positive-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "    s = list(map(lambda x: x[:-1], s))\n",
    "with open(\"../toxic_words.txt\", \"r\") as f:\n",
    "    ss = f.readlines()\n",
    "    s += list(map(lambda x: x[:-1], ss))\n",
    "pos_complex_tokens = group_by_first_token(s)\n",
    "\n",
    "\n",
    "def get_mask_fast(inp : str, bad_words = neg_complex_tokens, min_bad_score=0, aggressive=True):\n",
    "    sentences = [tokenizer.encode(inp, add_special_tokens=True)]\n",
    "    sentences_torch = torch.tensor(sentences)\n",
    "    masks = torch.zeros_like(sentences_torch)\n",
    "    \n",
    "    for sent_id, sent in enumerate(sentences):\n",
    "        for first_tok_id, tok in enumerate(sent):\n",
    "            for hypothesis in bad_words.get(tok, []):\n",
    "                if sent[first_tok_id: (first_tok_id + len(hypothesis))] == hypothesis:\n",
    "                    for step in range(len(hypothesis)):\n",
    "                        masks[sent_id, first_tok_id + step] = 1\n",
    "        if sum(masks[sent_id].numpy()) == 0 or aggressive:\n",
    "            scored_words = []\n",
    "            for indices, word in toks_to_words(sent):\n",
    "                score = word2coef.get(word)\n",
    "                if score:\n",
    "                    scored_words.append([indices, word, score])\n",
    "            if scored_words:\n",
    "                max_score = max(s[2] for s in scored_words)\n",
    "                if max_score > min_bad_score:\n",
    "                    for indices, word, score in scored_words:\n",
    "                        if score >= max(min_bad_score, max_score * 0.5):\n",
    "                            masks[sent_id, indices] = 1\n",
    "\n",
    "    return sentences_torch, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {v: k for k, v in tokenizer.vocab.items()}\n",
    "\n",
    "def toks_to_words(token_ids):\n",
    "    \"\"\" Merge subword tokens into whole words \"\"\"\n",
    "    indices = []\n",
    "    for i, token_id in enumerate(token_ids):\n",
    "        token_text = v[token_id]\n",
    "        if token_text.startswith('##'):\n",
    "            indices.append(i)\n",
    "        else:\n",
    "            if indices:\n",
    "                toks = [v[token_ids[t]] for t in indices]\n",
    "                word = ''.join([toks[0]] + [t[2:] for t in toks[1:]])\n",
    "                yield indices, word\n",
    "            indices = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2122, 18294,  9152, 13327,  2015,  2024,  2035, 11693,  6843,\n",
      "          2015,   102]])\n",
      "tensor([[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "toks, masks = get_mask_fast('These filthy niggers are all beggars', neg_complex_tokens)\n",
    "print(toks)\n",
    "print(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " [CLS] these **filthy niggers** are all **beggar**s [SEP]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_mask(toks, masks, inv_voc=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 6), (8, 10)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = []\n",
    "tox = False\n",
    "for idx, tok in enumerate(masks[0]):\n",
    "    if not tox and tok:\n",
    "        first = idx\n",
    "        tox = True\n",
    "    if tox and not tok:\n",
    "        spans.append((first, idx))\n",
    "        tox = False\n",
    "if tox:\n",
    "    spans.append((first, idx))\n",
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filthy niggers'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(toks[0][spans[0][0]: spans[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import get_masked_tokens_from_tagged_text, preprocess_tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "under = tokenizer.encode('_', add_special_tokens=False)[0]\n",
    "toks2 = toks[0].tolist()\n",
    "b, e = spans[0]\n",
    "toks2.insert(e, under)\n",
    "toks2.insert(e, under)\n",
    "toks2.insert(b, under)\n",
    "toks2.insert(b, under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101, 19424,  1044, 22571, 10085, 28884,  1010, 13350,  2024,  9202,\n",
       "            102]]),\n",
       " tensor([[0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0]]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 21)], 'disgusting_hypocrites , liberals are horrible')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_masked_tokens_from_tagged_text('__disgusting_hypocrites__ , liberals are horrible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 5006, 102, 2129, 2024, 2017, 102]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('hello billy [SEP] how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, <isanlp.annotation_repr.CSentence at 0x7f7fc4db5e50>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text = '__disgustinghypocrites__, liberals are horrible' \n",
    "get_masked_tokens_from_tagged_text(tagged_text)\n",
    "preprocess_tagged_text(tagged_text, ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-7f797ca65051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[MASK] , liberals are horrible'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "raw_text = '[MASK] , liberals are horrible'\n",
    "predictor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaskedTokenPredictorBert' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-f45a6bb0f0fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaskedTokenPredictorBert' object has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "predictor.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import masked_token_predictor_bert\n",
    "reload(masked_token_predictor_bert)\n",
    "from masked_token_predictor_bert import MaskedTokenPredictorBert\n",
    "\n",
    "from predict import analyze_tagged_text\n",
    "\n",
    "predictor = MaskedTokenPredictorBert(model, tokenizer, max_len=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '_',\n",
       " 'disgusting',\n",
       " '##hy',\n",
       " '##po',\n",
       " '##cr',\n",
       " '##ites',\n",
       " '_',\n",
       " '_',\n",
       " ',',\n",
       " 'liberals',\n",
       " 'are',\n",
       " 'mother',\n",
       " '##fu',\n",
       " '##cking',\n",
       " 'horrible']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor._bpe_tokenizer.tokenize(tagged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['disgusting', ',', 'liberals', 'are', 'horrible', '.']] [0] ['disgusting', 'h', '##yp', '##oc', '##rites']\n"
     ]
    }
   ],
   "source": [
    "def convert_mask(tok_ids, mask_ids, tokenizer, duplicate=False):\n",
    "    toks_tmp = [tokenizer.convert_ids_to_tokens(tok_ids[0])[1:-1]]\n",
    "    mask_pos = None\n",
    "    toks = []\n",
    "    mask_toks = []\n",
    "    has_mask = False\n",
    "    for i, is_masked in enumerate(mask_ids[0][1:-1]):\n",
    "        if is_masked:\n",
    "            mask_toks.append(toks_tmp[0][i])\n",
    "        if not has_mask:\n",
    "            if is_masked:\n",
    "                has_mask = True\n",
    "                mask_pos = [i]\n",
    "            toks.append(toks_tmp[0][i])\n",
    "        else:\n",
    "            if not is_masked:\n",
    "                toks.extend(toks_tmp[0][i:])\n",
    "                break\n",
    "    toks = [toks]\n",
    "    \n",
    "    if duplicate:\n",
    "        toks = [toks_tmp[0] + ['[SEP]'] + toks[0]]\n",
    "        mask_pos[0] += len(toks_tmp[0]) + 1\n",
    "    return toks, mask_pos, mask_toks\n",
    "\n",
    "tok_ids, mask_ids = get_mask_fast('disgusting hypocrites, liberals are horrible.')\n",
    "toks, mask_pos, mask_toks = convert_mask(tok_ids, mask_ids, tokenizer, duplicate=False)\n",
    "print(toks, mask_pos, mask_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['disgusting', 'h', '##yp', '##oc', '##rites', ',', 'liberals', 'are', 'horrible', '.', '[SEP]', 'disgusting', ',', 'liberals', 'are', 'horrible', '.']]\n",
      "[11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[['in', 'other', 'words'],\n",
       "   'yes',\n",
       "   ['in', 'any', 'event'],\n",
       "   ['of', 'course'],\n",
       "   ['in', 'my', 'opinion'],\n",
       "   ['of', 'course', 'not'],\n",
       "   'no',\n",
       "   ['in', 'other', '##words'],\n",
       "   ['in', 'other', 'news'],\n",
       "   ['in', 'my', 'experience'],\n",
       "   ['in', 'my', 'view'],\n",
       "   ['in', 'any', 'case'],\n",
       "   ['i', 'agree'],\n",
       "   ['in', 'my', 'book'],\n",
       "   ['i', 'mean'],\n",
       "   ['and', 'yes'],\n",
       "   ['in', 'fact'],\n",
       "   ['i', 'know'],\n",
       "   ['in', 'truth'],\n",
       "   ['i', 'repeat'],\n",
       "   ['.', 'yes'],\n",
       "   ['i', 'said'],\n",
       "   'well',\n",
       "   'actually',\n",
       "   'also',\n",
       "   'indeed',\n",
       "   'but',\n",
       "   'sadly',\n",
       "   'and',\n",
       "   'so']],\n",
       " [[10.072719097137451,\n",
       "   9.176839,\n",
       "   8.418205261230469,\n",
       "   8.19283413887024,\n",
       "   8.189598242441813,\n",
       "   8.045784870783487,\n",
       "   8.012597,\n",
       "   7.990880489349365,\n",
       "   7.918407281239827,\n",
       "   7.812328497568767,\n",
       "   7.74386199315389,\n",
       "   7.584173520406087,\n",
       "   7.5116565227508545,\n",
       "   7.494822343190511,\n",
       "   7.481910467147827,\n",
       "   7.467418909072876,\n",
       "   7.275264263153076,\n",
       "   6.773961305618286,\n",
       "   6.773752212524414,\n",
       "   6.76964259147644,\n",
       "   6.467712879180908,\n",
       "   6.4507715702056885,\n",
       "   6.42548,\n",
       "   6.1643615,\n",
       "   5.7537913,\n",
       "   5.679646,\n",
       "   5.62532,\n",
       "   5.527266,\n",
       "   5.24821,\n",
       "   5.2366247]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.generate(toks, mask_pos, n_tokens=[1, 2, 3], n_top=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_units': 1, 'n_top': 10, 'fix_multiunit': False, 'mask_token': False, 'n_tokens': [1, 2, 3], 'multiunit_lookup': 200, 'max_multiunit': 50, 'Cs': None}\n",
      "[['disgusting', ',', 'liberals', 'are', 'mother', '##fu', '##cking', 'horrible']]\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['in', 'other', 'words'],\n",
       " ['in', 'my', 'opinion'],\n",
       " ['in', 'other', '##words'],\n",
       " ['in', 'my', 'view'],\n",
       " ['in', 'my', 'experience'],\n",
       " ['in', 'my', 'book'],\n",
       " 'yes',\n",
       " ['in', 'other', 'news'],\n",
       " ['i', 'agree'],\n",
       " ['in', 'fact']]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text = '__disgustinghypocrites__, liberals are motherfucking horrible' \n",
    "\n",
    "texts, scores, positions = analyze_tagged_text(tagged_text, predictor, ppl, \n",
    "                                                                         n_top=10,\n",
    "                                                                         n_units=1,\n",
    "                                                                         n_tokens=[1, 2, 3],\n",
    "                                                                         max_multiunit=50,\n",
    "                                                                         fix_multiunit=False,\n",
    "                                                                         mask_token=False,\n",
    "                                                                         multiunit_lookup=200)\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = embed(positions.text)\n",
    "w = 3\n",
    "candidates = []\n",
    "for toks, score in zip(texts, scores):\n",
    "    cd = cosine(e, embed(' '.join(toks)))\n",
    "    candidates.append((toks, score, cd))\n",
    "\n",
    "candidates = sorted(candidates, key = lambda s: -s[1]-s[2]*w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017',\n",
       " '2016',\n",
       " ['3', '.', 'yes'],\n",
       " ['5', '.', 'yes'],\n",
       " ['2', '.', 'yes'],\n",
       " ['4', '.', 'yes'],\n",
       " ['1', '.', 'yes'],\n",
       " ['3', '.', 'no'],\n",
       " ['5', '.', 'no'],\n",
       " ['2', '.', 'no']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disgustinghypocrites'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2017', 7.314762, 0.0),\n",
       " ('2016', 6.9734936, 0.0),\n",
       " (['3', '.', 'yes'], 6.943620999654134, 0.0),\n",
       " (['5', '.', 'yes'], 6.915168444315593, 0.0),\n",
       " (['2', '.', 'yes'], 6.859041849772136, 0.0),\n",
       " (['4', '.', 'yes'], 6.778350989023845, 0.0),\n",
       " (['1', '.', 'yes'], 6.717874844868978, 0.0),\n",
       " (['3', '.', 'no'], 6.686502297719319, 0.0),\n",
       " (['5', '.', 'no'], 6.672283172607422, 0.0),\n",
       " (['2', '.', 'no'], 6.584537506103516, 0.0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypotheses(text, top=10, duplicate=False, mask_token=False, reorder=True, sim_coef=30):\n",
    "    tokenizer = predictor._bpe_tokenizer\n",
    "    tok_ids, mask_ids = get_mask_fast(text)\n",
    "    toks, mask_pos, mask_toks = convert_mask(tok_ids, mask_ids, tokenizer=tokenizer, duplicate=duplicate)\n",
    "    mask_text = tokenizer.convert_tokens_to_string(mask_toks)\n",
    "    \n",
    "    texts, scores = predictor.generate(toks, mask_pos, n_top=top,\n",
    "                                                                         n_units=1,\n",
    "                                                                         n_tokens=[1, 2, 3],\n",
    "                                                                         max_multiunit=50,\n",
    "                                                                         fix_multiunit=False,\n",
    "                                                                         mask_token=mask_token,\n",
    "                                                                         multiunit_lookup=200)\n",
    "    texts = texts[0]\n",
    "    scores = scores[0]\n",
    "    \n",
    "    e = embed(mask_text)\n",
    "    \n",
    "    candidates = [(fill_words, score, cosine(e, embed(' '.join(fill_words)))) for fill_words, score in zip(texts, scores)]\n",
    "    if reorder:\n",
    "        candidates = sorted(candidates, key=lambda x: x[1] + x[2] * sim_coef, reverse=True)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['they', 'are', 'all', 'com', '##mies', 'who', 'hate', 'the', 'usa', '.']]\n",
      "[6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['want', 'war', 'on'], 9.738919576009115, 0.5378161279652228),\n",
       " (['want', 'war', 'with'], 9.051971117655436, 0.548173074628717),\n",
       " (['disagree', 'with'], 10.653357744216919, 0.48147376370278683),\n",
       " (['live', 'in'], 12.780094146728516, 0.40713618842099875),\n",
       " (['want', 'to', 'dominate'], 9.306215286254883, 0.5193634982216501),\n",
       " (['want', 'to', 'rule'], 9.457503000895182, 0.5114022576356618),\n",
       " (['live', 'out', 'of'], 9.491169134775797, 0.49341802487782876),\n",
       " (['want', 'to', 'control'], 8.995625495910645, 0.4922933683988261),\n",
       " (['have', 'come', 'to'], 10.028025309244791, 0.4577996636587268),\n",
       " (['come', 'to'], 10.062110900878906, 0.44948852617858986),\n",
       " (['live', 'outside'], 11.129491329193115, 0.4021484093942314),\n",
       " (['live', 'out', 'in'], 9.154391765594482, 0.45301393233243925),\n",
       " (['live', 'illegally', 'in'], 10.332592964172363, 0.4111384195666097),\n",
       " (['live', 'here', 'in'], 9.75853157043457, 0.42455462525992327),\n",
       " (['came', 'to'], 10.453114986419678, 0.4012123880669218),\n",
       " (['live', 'within'], 9.459606170654297, 0.4105221110258424),\n",
       " (['work', 'for'], 10.343756198883057, 0.3662149399736128),\n",
       " (['exist', 'in'], 9.845892429351807, 0.3808379191464387),\n",
       " (['fought', 'for'], 9.644322633743286, 0.37705461522034645),\n",
       " (['work', 'in'], 10.138545513153076, 0.34276983942811845),\n",
       " ('failed', 8.136024, 0.39524562926960405),\n",
       " ('dominate', 8.055493, 0.39449972474383266),\n",
       " ('raid', 5.5816073, 0.43469671362245027),\n",
       " ('divide', 5.350295, 0.43434345182251133),\n",
       " ('fail', 5.7819057, 0.40187821580786426),\n",
       " ('rule', 9.253026, 0.2843814952181399),\n",
       " ('run', 9.956785, 0.25859222377836644),\n",
       " ('invaded', 6.0917344, 0.3873772381881516),\n",
       " ('control', 9.39328, 0.2564777870119844),\n",
       " ('created', 7.024441, 0.3328922258254446),\n",
       " ('rigged', 6.4839897, 0.33100435105088366),\n",
       " ('contaminated', 5.4098186, 0.36645562327592196),\n",
       " ('fear', 5.967645, 0.3439681279443084),\n",
       " ('want', 6.686778, 0.31844462804296464),\n",
       " ('serve', 6.89561, 0.3052109974084395),\n",
       " ('betrayed', 5.702249, 0.3236236519803087),\n",
       " ('sabotage', 5.455494, 0.3279318934712374),\n",
       " ('attack', 6.0006046, 0.3078213289865532),\n",
       " ('overthrow', 6.9021244, 0.27591558458241366),\n",
       " ('destroyed', 6.086162, 0.3025730584983646),\n",
       " ('have', 5.7065945, 0.29774316924089883),\n",
       " ('own', 7.3628554, 0.23517747321838423),\n",
       " ('controlled', 6.0886555, 0.2685426637942837),\n",
       " ('love', 6.6399846, 0.24850631387318975),\n",
       " ('support', 6.524621, 0.24318162722422315),\n",
       " ('ruled', 5.36684, 0.2775482534168791),\n",
       " ('robbed', 5.6947913, 0.26085214591822165),\n",
       " ('crash', 5.7070637, 0.25814004461014395),\n",
       " ('rob', 5.41156, 0.24466242392208631),\n",
       " ('shell', 5.550017, 0.22722643997460537)]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hypotheses('they are all commies who hate the usa.', duplicate=False, mask_token=True, top=50, reorder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['*', '*', '*'], 7.921519120534261, 0.14069499121669057),\n",
       " (['.', '.', '.'], 7.655266761779785, 0.1252409178558933),\n",
       " (['=', '=', '='], 7.758999745051066, -0.003951449800087439),\n",
       " (['=', '=', '_'], 7.373194297154744, 0.05725328546334192),\n",
       " (['_', '_'], 6.9894938468933105, 0.17686531443781797),\n",
       " (['=', '='], 7.453720569610596, -0.003951459998446594),\n",
       " (['#', '#', '#'], 7.324734528859456, 0.013518912351355083),\n",
       " (['=', '_', '='], 7.1484889189402265, 0.05725326822132314),\n",
       " (['^', '^', '^'], 7.036758581797282, 0.05811795687572079),\n",
       " (['#', '#', '%'], 6.957322279612224, -0.006257355213289987)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text = '__disgustinghypocrites__ , liberals are horrible' \n",
    "_analyze_tagged_text(tagged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['*', '*', '*'], 7.921519120534261, 0.14069499121669057),\n",
       " (['.', '.', '.'], 7.655266761779785, 0.1252409178558933),\n",
       " (['=', '=', '='], 7.758999745051066, -0.003951449800087439),\n",
       " (['=', '=', '_'], 7.373194297154744, 0.05725328546334192),\n",
       " (['_', '_'], 6.9894938468933105, 0.17686531443781797),\n",
       " (['=', '='], 7.453720569610596, -0.003951459998446594),\n",
       " (['#', '#', '#'], 7.324734528859456, 0.013518912351355083),\n",
       " (['=', '_', '='], 7.1484889189402265, 0.05725326822132314),\n",
       " (['^', '^', '^'], 7.036758581797282, 0.05811795687572079),\n",
       " (['#', '#', '%'], 6.957322279612224, -0.006257355213289987)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_analyze_tagged_text('disgusting hypocrites , liberals are __horrible__.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['*', '*', '*'], 7.921519120534261, 0.14069499121669057),\n",
       " (['.', '.', '.'], 7.655266761779785, 0.1252409178558933),\n",
       " (['=', '=', '='], 7.758999745051066, -0.003951449800087439),\n",
       " (['=', '=', '_'], 7.373194297154744, 0.05725328546334192),\n",
       " (['_', '_'], 6.9894938468933105, 0.17686531443781797),\n",
       " (['=', '='], 7.453720569610596, -0.003951459998446594),\n",
       " (['#', '#', '#'], 7.324734528859456, 0.013518912351355083),\n",
       " (['=', '_', '='], 7.1484889189402265, 0.05725326822132314),\n",
       " (['^', '^', '^'], 7.036758581797282, 0.05811795687572079),\n",
       " (['#', '#', '%'], 6.957322279612224, -0.006257355213289987)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = _analyze_tagged_text('they are all commies who __hate__ the usa.')\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_analyze_tagged_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-8474f29d1aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_analyze_tagged_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'they are all commies who __hate__ the usa.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_analyze_tagged_text' is not defined"
     ]
    }
   ],
   "source": [
    "e = embed('hate')\n",
    "\n",
    "candidates = _analyze_tagged_text('they are all commies who __hate__ the usa.')\n",
    "for c in candidates:\n",
    "    print(c[0], c[1], cosine(e, embed(' '.join(c[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['*', '*', '*'] 7.921519120534261 0.015660406447927728\n",
      "['.', '.', '.'] 7.655266761779785 0.03725754125051693\n",
      "['=', '=', '='] 7.758999745051066 -0.05899542456714306\n",
      "['=', '=', '_'] 7.373194297154744 -0.002261871014656805\n",
      "['_', '_'] 6.9894938468933105 0.14047101594395606\n",
      "['=', '='] 7.453720569610596 -0.058995433066475644\n",
      "['#', '#', '#'] 7.324734528859456 -0.018090612088231484\n",
      "['=', '_', '='] 7.1484889189402265 -0.0022618706804704712\n",
      "['^', '^', '^'] 7.036758581797282 0.047306874740281016\n",
      "['#', '#', '%'] 6.957322279612224 -0.04946179312835721\n"
     ]
    }
   ],
   "source": [
    "e = embed('disgusting hypocrites')\n",
    "\n",
    "candidates = _analyze_tagged_text( '__disgustinghypocrites__ , liberals are horrible' )\n",
    "mcd = 0\n",
    "best = None\n",
    "for c in candidates:\n",
    "    cd = cosine(e, embed(' '.join(c[0])))\n",
    "    if cd > mcd:\n",
    "        mcd = cd\n",
    "        best = c\n",
    "    print(c[0], c[1], cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2829016397951324 (['my', 'goodness'], 6.221156477928162)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['*', '*', '*'] 7.921519120534261 -0.07281956958562612\n",
      "['.', '.', '.'] 7.655266761779785 -0.21645356457928608\n",
      "['=', '=', '='] 7.758999745051066 -0.09866870169018566\n",
      "['=', '=', '_'] 7.373194297154744 -0.13607912444422654\n",
      "['_', '_'] 6.9894938468933105 -0.150988986105091\n",
      "['=', '='] 7.453720569610596 -0.09866870977424569\n",
      "['#', '#', '#'] 7.324734528859456 -0.07327265752233413\n",
      "['=', '_', '='] 7.1484889189402265 -0.1360791249010521\n",
      "['^', '^', '^'] 7.036758581797282 0.07723455771282743\n",
      "['#', '#', '%'] 6.957322279612224 -0.08551658442812683\n",
      "0.07723455771282743 (['^', '^', '^'], 7.036758581797282, 0.05811795687572079)\n"
     ]
    }
   ],
   "source": [
    "e = embed('imbecile')\n",
    "\n",
    "candidates = _analyze_tagged_text( 'He is an economic __imbecile__.' )\n",
    "mcd = 0\n",
    "best = None\n",
    "for c in candidates:\n",
    "    cd = cosine(e, embed(' '.join(c[0])))\n",
    "    if cd > mcd:\n",
    "        mcd = cd\n",
    "        best = c\n",
    "    print(c[0], c[1], cd)\n",
    "\n",
    "print(mcd, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3k",
   "language": "python",
   "name": "p3k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
