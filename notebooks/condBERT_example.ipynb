{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip3 install transformers==2.8.0\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Sp3QLnEUSHMk3q81YJKAPiT-17EAKMVb' -O condBERT.zip\n",
    "!unzip condBERT.zip\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_WEIGHTS = 'ru_cond_bert_geotrend/checkpoint-9000/pytorch_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_DIRNAME = 'ru_vocabularies_geotrend' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "def add_sys_path(p):\n",
    "    p = os.path.abspath(p)\n",
    "    print(p)\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/workspace/style_transfer/condBERT/multiword\n"
     ]
    }
   ],
   "source": [
    "add_sys_path('multiword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from condbert import CondBertRewriter\n",
    "from choosers import EmbeddingSimilarityChooser\n",
    "from masked_token_predictor_bert import MaskedTokenPredictorBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Geotrend/bert-base-ru-cased'\n",
    "tokenizer_ru = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "model_dict = torch.load(BERT_WEIGHTS, map_location=device)\n",
    "\n",
    "# You can experiment with zero-shot setup or load pretrained weights\n",
    "# model.load_state_dict(model_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of pre-defined toxicity weights of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOCAB_DIRNAME + \"/negative-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "negative_words = list(map(lambda x: x[:-1], s))\n",
    "\n",
    "with open(VOCAB_DIRNAME + \"/positive-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "positive_words = list(map(lambda x: x[:-1], s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(VOCAB_DIRNAME + '/word2coef.pkl', 'rb') as f:\n",
    "    word2coef = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_toxicities = []\n",
    "with open(VOCAB_DIRNAME + '/token_toxicities.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        token_toxicities.append(float(line))\n",
    "token_toxicities = np.array(token_toxicities)\n",
    "token_toxicities = np.maximum(0, np.log(1/(1/token_toxicities-1)))   # log odds ratio\n",
    "\n",
    "# discourage meaningless tokens\n",
    "for tok in ['.', ',', '-']:\n",
    "    token_toxicities[tokenizer_ru.encode(tok)][1] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_logits(logits):\n",
    "    return logits - token_toxicities * 100\n",
    "\n",
    "predictor = MaskedTokenPredictorBert(model, tokenizer_ru, max_len=250, device=device, label=0, contrast_penalty=0.0, logits_postprocessor=adjust_logits)\n",
    "\n",
    "editor = CondBertRewriter(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer_ru,\n",
    "    device=device,\n",
    "    neg_words=negative_words,\n",
    "    pos_words=positive_words,\n",
    "    word2coef=word2coef,\n",
    "    token_toxicities=token_toxicities,\n",
    "    predictor=predictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings\n",
    "import gensim\n",
    "\n",
    "def cosine(v1, v2):\n",
    "    return np.dot(v1, v2) / np.sqrt(sum(v1**2) * sum(v2**2) + 1e-10)\n",
    "\n",
    "class RuEmbeddingSimilarityChooser:\n",
    "    def __init__(self, sim_coef=100, tokenizer=None):\n",
    "        self.embedding = gensim.models.KeyedVectors.load('../ru_fasttext/model.model')\n",
    "        self.sim_coef = sim_coef\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def embed(self, text):\n",
    "        toks = [tok.text for tok in Sentence(text).tokens]\n",
    "        toks = [self.embedding[tok] for tok in toks]\n",
    "        return np.mean(toks, axis=0)\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        if isinstance(tokens, str):\n",
    "            return tokens\n",
    "        if self.tokenizer:\n",
    "            return self.tokenizer.convert_tokens_to_string(tokens)\n",
    "        return ' '.join(tokens).replace(' ##', '')\n",
    "\n",
    "    def __call__(self, hypotheses, original=None, scores=None, **kwargs):\n",
    "        e = self.embed(self.decode(original))\n",
    "        candidates = [\n",
    "            (fill_words, score, cosine(e, self.embed(self.decode(fill_words)))) \n",
    "            for fill_words, score in zip(hypotheses, scores)\n",
    "        ]\n",
    "        candidates = sorted(candidates, key=lambda x: x[1] + x[2] * self.sim_coef, reverse=True)\n",
    "        return candidates[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chooser = RuEmbeddingSimilarityChooser(sim_coef=10, tokenizer=tokenizer_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference exmple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Ты дурак и ничего не понимаешь. Что значит по-твоему построить дорогу?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change locally by one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ты дурак и ничего не понимаешь. Что значит по-твоему построить дорогу?\n",
      "Ты дурак и ничего не понимаешь . Что значит по - твоему построить дорогу ?\n"
     ]
    }
   ],
   "source": [
    "print(editor.translate(text, prnt=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try generate multi-word substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ты знаешь и ничего не понимаешь . Что значит по - прежнему построить дорогу ?\n"
     ]
    }
   ],
   "source": [
    "print(editor.replacement_loop(text, verbose=False, chooser=chooser, n_tokens=(1,2,3), n_top=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
